{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ee7ff5ee-50ed-47e5-b21a-2380344dcbdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "78190a05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import seaborn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a9a8ad31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f9975c3f",
   "metadata": {
    "lines_to_next_cell": 1,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "\n",
    "    def __init__(self,\n",
    "                 model: torch.nn.Module,\n",
    "                 device: torch.device,\n",
    "                 criterion: torch.nn.Module,\n",
    "                 optimizer: torch.optim.Optimizer,\n",
    "                 training_DataLoader: torch.utils.data.Dataset,\n",
    "                 validation_DataLoader: None,\n",
    "                 # lr_scheduler: torch.optim.lr_scheduler = None,\n",
    "                 epochs: int = 100,\n",
    "                 epoch: int = 0,\n",
    "                 notebook: bool = False,\n",
    "                 path2write: str = None,\n",
    "                 save_best=False,\n",
    "                 save_final=True,\n",
    "                 save_interval=10,\n",
    "                 checkpoint_start_epoch=50\n",
    "                 ):\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        # self.lr_scheduler = lr_scheduler\n",
    "        self.training_DataLoader = training_DataLoader\n",
    "        self.validation_DataLoader = validation_DataLoader\n",
    "        self.device = device\n",
    "        self.epochs = epochs\n",
    "        self.epoch = epoch\n",
    "        self.notebook = notebook\n",
    "        self.path2write = path2write\n",
    "        LOG_DIR = os.path.join(path2write, 'Log')  # path2write + 'Log/'\n",
    "        self.writer_train = SummaryWriter(os.path.join(LOG_DIR, \"train\"))\n",
    "        self.writer_val = SummaryWriter(os.path.join(LOG_DIR, \"val\"))\n",
    "        self.check_point_path = os.path.join(path2write, 'check_points')\n",
    "        if not os.path.exists(self.check_point_path):\n",
    "            os.makedirs(self.check_point_path)\n",
    "        self.save_best = save_best\n",
    "        self.save_final = save_final\n",
    "        self.save_interval = save_interval\n",
    "        self.checkpoint_start_epoch = checkpoint_start_epoch\n",
    "        self.training_loss = []\n",
    "        self.validation_loss = []\n",
    "        self.learning_rate = []\n",
    "        self.training_accuracy = []\n",
    "        self.validation_accuracy = []\n",
    "\n",
    "    def run_trainer(self):\n",
    "        self.model.to(self.device)\n",
    "        #         print(next(self.model.parameters()).device)\n",
    "        if self.notebook:\n",
    "            print('Notebook')\n",
    "            from tqdm.notebook import tqdm, trange\n",
    "        else:\n",
    "            from tqdm import tqdm, trange\n",
    "        #         print(self.epochs)\n",
    "        progressbar = trange(self.epochs, desc='Progress', disable=True)  # don't show progressbar\n",
    "        loss_max = None\n",
    "        for epoch in progressbar:\n",
    "            print(f'Epoch - {epoch}')\n",
    "\n",
    "            # Training Block\n",
    "            train_loss, train_accuracy = self._train()\n",
    "            self.writer_train.add_scalar(\"Train Loss\", train_loss, epoch)\n",
    "            self.writer_train.add_scalar(\"Train Accuracy\", train_accuracy, epoch)\n",
    "\n",
    "            # Val Block\n",
    "            val_loss, val_accuracy = self._validate()\n",
    "            self.writer_val.add_scalar(\"Val Loss\", val_loss, epoch)\n",
    "            self.writer_val.add_scalar(\"Val Accuracy\", val_accuracy, epoch)\n",
    "\n",
    "            # lr\n",
    "            self.writer_train.add_scalar(\"Learning Rate\", self.optimizer.param_groups[0]['lr'], epoch)\n",
    "\n",
    "            print(\n",
    "                'Epoch - {} Train Loss - {:.6f} Val Loss - {:.6f} Train Accuracy - {:.6f} Val Accuracy - {:.6f}'.format(\n",
    "                    epoch, train_loss, val_loss, train_accuracy, val_accuracy))\n",
    "            if self.save_final:\n",
    "                if epoch == self.epochs - 1:\n",
    "                    model_name = 'epoch-{}-loss{:.6f}'.format(epoch, val_loss)\n",
    "                    torch.save(self.model.state_dict(), os.path.join(self.check_point_path, model_name))\n",
    "            loss_max = val_loss\n",
    "        sensitivity = self.sensitivity()\n",
    "        return train_loss, train_accuracy, val_loss, val_accuracy, sensitivity\n",
    "        # return self.training_loss, self.validation_loss, self.model, self.training_accuracy, self.validation_accuracy\n",
    "\n",
    "    def _train(self):\n",
    "\n",
    "        self.model.train()\n",
    "        train_losses = []\n",
    "        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),\n",
    "                          disable=True)\n",
    "        batch_acc = 0\n",
    "        for i, (x, y) in batch_iter:\n",
    "            input, target = x.type(torch.float32).to(self.device), y.type(torch.float32).to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "            target = target.type(torch.LongTensor).to(self.device)\n",
    "            output = self.model(input)\n",
    "            loss = self.criterion(output, target)\n",
    "            train_losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # max of prob\n",
    "            pred = pred.flatten()\n",
    "            batch_acc += torch.mean(pred.eq(target.view_as(pred)).type(torch.FloatTensor))\n",
    "\n",
    "        accuracy = batch_acc / len(self.training_DataLoader)\n",
    "        self.training_loss.append(np.mean(train_losses))  # Mean batch loss\n",
    "        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])\n",
    "        self.training_accuracy.append(accuracy)\n",
    "\n",
    "        batch_iter.close()  # clean up the bar\n",
    "        return np.mean(train_losses), accuracy\n",
    "\n",
    "    def _validate(self):\n",
    "\n",
    "        self.model.eval()\n",
    "        valid_losses = []\n",
    "        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'validation', total=len(self.validation_DataLoader),\n",
    "                          disable=True)\n",
    "        batch_acc = 0\n",
    "        for i, (x, y) in batch_iter:\n",
    "            input, target = x.type(torch.float32).to(self.device), y.to(self.device)\n",
    "            with torch.no_grad():\n",
    "                output = self.model(input)\n",
    "                target = target.type(torch.LongTensor).to(self.device)\n",
    "                loss = self.criterion(output, target)\n",
    "                valid_losses.append(loss.item())\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                batch_acc += torch.mean(pred.eq(target.view_as(pred)).type(torch.FloatTensor)).item()\n",
    "\n",
    "        accuracy = batch_acc / len(self.validation_DataLoader)\n",
    "        self.validation_loss.append(np.mean(valid_losses))\n",
    "        self.validation_accuracy.append(accuracy)\n",
    "        batch_iter.close()\n",
    "        return np.mean(valid_losses), accuracy\n",
    "\n",
    "    def sensitivity(self):\n",
    "        num = 0\n",
    "        FNorm = 0\n",
    "        for p in self.model.parameters():\n",
    "            grad = 0.0\n",
    "            if p.grad is not None:\n",
    "                num += 1\n",
    "                grad = p.grad\n",
    "                FNorm += torch.linalg.norm(grad).cpu().numpy()\n",
    "        return FNorm / num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "345a1fe0-37cb-4a90-a7d0-e876312cd733",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path2write = os.path.expanduser(\"~/my_logs\")  # This will create a 'my_logs' directory in your home directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "24d5cda8",
   "metadata": {
    "lines_to_next_cell": 1,
    "tags": []
   },
   "outputs": [],
   "source": [
    "gpu_id = 0\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "lr = 1e-4\n",
    "epochs =  15\n",
    "notebook = True\n",
    "checkpoint_start_epoch = 5 #Not using\n",
    "path2write = r\"/Users/ramya/Desktop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "822e96d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNN2(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "    self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    self.dense1 = nn.Linear(32*14*14, 128)\n",
    "    self.dense2 = nn.Linear(128, 10)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.conv1(x)\n",
    "    x = F.relu(x)\n",
    "    x = self.pool1(x)\n",
    "    x = x.view(x.shape[0], -1)\n",
    "    x = self.dense1(x)\n",
    "    x = self.dense2(x)\n",
    "    out = F.log_softmax(x)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3446a5b5-971a-4a77-a56e-a76876475046",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "path2write = tempfile.mkdtemp()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "35bc1818",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]/local_scratch/slurm.707385/ipykernel_654196/979612184.py:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook\n",
      "Epoch - 0\n",
      "Epoch - 0 Train Loss - 0.289530 Val Loss - 0.144010 Train Accuracy - 0.916600 Val Accuracy - 0.959800\n",
      "Epoch - 1\n",
      "Epoch - 1 Train Loss - 0.119026 Val Loss - 0.090531 Train Accuracy - 0.965550 Val Accuracy - 0.972300\n",
      "Epoch - 2\n",
      "Epoch - 2 Train Loss - 0.082189 Val Loss - 0.073536 Train Accuracy - 0.975983 Val Accuracy - 0.976700\n",
      "Epoch - 3\n",
      "Epoch - 3 Train Loss - 0.065142 Val Loss - 0.071108 Train Accuracy - 0.980283 Val Accuracy - 0.977500\n",
      "Epoch - 4\n",
      "Epoch - 4 Train Loss - 0.055208 Val Loss - 0.064226 Train Accuracy - 0.983133 Val Accuracy - 0.979500\n",
      "Epoch - 5\n",
      "Epoch - 5 Train Loss - 0.047766 Val Loss - 0.054830 Train Accuracy - 0.985667 Val Accuracy - 0.983200\n",
      "Epoch - 6\n",
      "Epoch - 6 Train Loss - 0.042008 Val Loss - 0.054808 Train Accuracy - 0.987167 Val Accuracy - 0.982300\n",
      "Epoch - 7\n",
      "Epoch - 7 Train Loss - 0.037747 Val Loss - 0.053245 Train Accuracy - 0.988650 Val Accuracy - 0.982400\n",
      "Epoch - 8\n",
      "Epoch - 8 Train Loss - 0.034735 Val Loss - 0.052380 Train Accuracy - 0.989250 Val Accuracy - 0.983400\n",
      "Epoch - 9\n",
      "Epoch - 9 Train Loss - 0.030402 Val Loss - 0.058427 Train Accuracy - 0.990683 Val Accuracy - 0.981300\n",
      "Epoch - 10\n",
      "Epoch - 10 Train Loss - 0.027050 Val Loss - 0.052950 Train Accuracy - 0.991800 Val Accuracy - 0.983800\n",
      "Epoch - 11\n",
      "Epoch - 11 Train Loss - 0.024407 Val Loss - 0.050572 Train Accuracy - 0.992567 Val Accuracy - 0.984800\n",
      "Epoch - 12\n",
      "Epoch - 12 Train Loss - 0.021788 Val Loss - 0.058816 Train Accuracy - 0.993383 Val Accuracy - 0.982100\n",
      "Epoch - 13\n",
      "Epoch - 13 Train Loss - 0.019842 Val Loss - 0.064136 Train Accuracy - 0.994100 Val Accuracy - 0.980900\n",
      "Epoch - 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [04:22<21:53, 262.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 14 Train Loss - 0.017608 Val Loss - 0.058687 Train Accuracy - 0.994850 Val Accuracy - 0.984500\n",
      "Notebook\n",
      "Epoch - 0\n",
      "Epoch - 0 Train Loss - 0.392191 Val Loss - 0.169826 Train Accuracy - 0.896983 Val Accuracy - 0.951777\n",
      "Epoch - 1\n",
      "Epoch - 1 Train Loss - 0.147243 Val Loss - 0.118667 Train Accuracy - 0.958100 Val Accuracy - 0.966853\n",
      "Epoch - 2\n",
      "Epoch - 2 Train Loss - 0.104538 Val Loss - 0.091860 Train Accuracy - 0.970133 Val Accuracy - 0.973343\n",
      "Epoch - 3\n",
      "Epoch - 3 Train Loss - 0.083073 Val Loss - 0.077427 Train Accuracy - 0.976383 Val Accuracy - 0.976837\n",
      "Epoch - 4\n",
      "Epoch - 4 Train Loss - 0.069783 Val Loss - 0.063426 Train Accuracy - 0.979233 Val Accuracy - 0.979732\n",
      "Epoch - 5\n",
      "Epoch - 5 Train Loss - 0.060391 Val Loss - 0.063698 Train Accuracy - 0.982300 Val Accuracy - 0.979433\n",
      "Epoch - 6\n",
      "Epoch - 6 Train Loss - 0.055126 Val Loss - 0.061159 Train Accuracy - 0.983783 Val Accuracy - 0.981230\n",
      "Epoch - 7\n",
      "Epoch - 7 Train Loss - 0.049165 Val Loss - 0.059270 Train Accuracy - 0.985783 Val Accuracy - 0.981330\n",
      "Epoch - 8\n",
      "Epoch - 8 Train Loss - 0.044904 Val Loss - 0.061927 Train Accuracy - 0.986950 Val Accuracy - 0.981030\n",
      "Epoch - 9\n",
      "Epoch - 9 Train Loss - 0.041566 Val Loss - 0.057504 Train Accuracy - 0.987417 Val Accuracy - 0.982428\n",
      "Epoch - 10\n",
      "Epoch - 10 Train Loss - 0.038029 Val Loss - 0.060133 Train Accuracy - 0.989067 Val Accuracy - 0.981230\n",
      "Epoch - 11\n",
      "Epoch - 11 Train Loss - 0.035074 Val Loss - 0.057981 Train Accuracy - 0.989833 Val Accuracy - 0.981829\n",
      "Epoch - 12\n",
      "Epoch - 12 Train Loss - 0.032562 Val Loss - 0.054000 Train Accuracy - 0.990433 Val Accuracy - 0.982827\n",
      "Epoch - 13\n",
      "Epoch - 13 Train Loss - 0.029990 Val Loss - 0.052334 Train Accuracy - 0.991450 Val Accuracy - 0.984225\n",
      "Epoch - 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [06:21<11:51, 177.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 14 Train Loss - 0.028374 Val Loss - 0.051795 Train Accuracy - 0.991567 Val Accuracy - 0.984525\n",
      "Notebook\n",
      "Epoch - 0\n",
      "Epoch - 0 Train Loss - 0.637958 Val Loss - 0.260511 Train Accuracy - 0.858514 Val Accuracy - 0.927512\n",
      "Epoch - 1\n",
      "Epoch - 1 Train Loss - 0.225896 Val Loss - 0.180283 Train Accuracy - 0.936945 Val Accuracy - 0.948972\n",
      "Epoch - 2\n",
      "Epoch - 2 Train Loss - 0.167017 Val Loss - 0.141969 Train Accuracy - 0.953097 Val Accuracy - 0.960344\n",
      "Epoch - 3\n",
      "Epoch - 3 Train Loss - 0.134371 Val Loss - 0.120584 Train Accuracy - 0.962925 Val Accuracy - 0.966377\n",
      "Epoch - 4\n",
      "Epoch - 4 Train Loss - 0.112940 Val Loss - 0.104863 Train Accuracy - 0.968411 Val Accuracy - 0.970134\n",
      "Epoch - 5\n",
      "Epoch - 5 Train Loss - 0.098312 Val Loss - 0.093266 Train Accuracy - 0.972692 Val Accuracy - 0.972706\n",
      "Epoch - 6\n",
      "Epoch - 6 Train Loss - 0.087520 Val Loss - 0.083368 Train Accuracy - 0.975652 Val Accuracy - 0.976068\n",
      "Epoch - 7\n",
      "Epoch - 7 Train Loss - 0.079228 Val Loss - 0.082032 Train Accuracy - 0.977962 Val Accuracy - 0.975969\n",
      "Epoch - 8\n",
      "Epoch - 8 Train Loss - 0.072238 Val Loss - 0.079786 Train Accuracy - 0.979278 Val Accuracy - 0.975574\n",
      "Epoch - 9\n",
      "Epoch - 9 Train Loss - 0.066802 Val Loss - 0.070311 Train Accuracy - 0.980766 Val Accuracy - 0.979035\n",
      "Epoch - 10\n",
      "Epoch - 10 Train Loss - 0.061854 Val Loss - 0.068873 Train Accuracy - 0.982126 Val Accuracy - 0.979233\n",
      "Epoch - 11\n",
      "Epoch - 11 Train Loss - 0.057556 Val Loss - 0.071389 Train Accuracy - 0.983326 Val Accuracy - 0.977848\n",
      "Epoch - 12\n",
      "Epoch - 12 Train Loss - 0.054497 Val Loss - 0.061916 Train Accuracy - 0.984503 Val Accuracy - 0.981112\n",
      "Epoch - 13\n",
      "Epoch - 13 Train Loss - 0.051728 Val Loss - 0.060891 Train Accuracy - 0.985430 Val Accuracy - 0.981705\n",
      "Epoch - 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [07:45<06:45, 135.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 14 Train Loss - 0.048911 Val Loss - 0.063498 Train Accuracy - 0.985791 Val Accuracy - 0.981112\n",
      "Notebook\n",
      "Epoch - 0\n",
      "Epoch - 0 Train Loss - 1.228585 Val Loss - 0.590994 Train Accuracy - 0.771093 Val Accuracy - 0.880699\n",
      "Epoch - 1\n",
      "Epoch - 1 Train Loss - 0.457983 Val Loss - 0.348198 Train Accuracy - 0.891778 Val Accuracy - 0.914987\n",
      "Epoch - 2\n",
      "Epoch - 2 Train Loss - 0.321654 Val Loss - 0.275639 Train Accuracy - 0.913445 Val Accuracy - 0.925850\n",
      "Epoch - 3\n",
      "Epoch - 3 Train Loss - 0.264609 Val Loss - 0.240190 Train Accuracy - 0.927001 Val Accuracy - 0.932370\n",
      "Epoch - 4\n",
      "Epoch - 4 Train Loss - 0.230231 Val Loss - 0.207275 Train Accuracy - 0.935470 Val Accuracy - 0.944083\n",
      "Epoch - 5\n",
      "Epoch - 5 Train Loss - 0.203848 Val Loss - 0.187866 Train Accuracy - 0.942830 Val Accuracy - 0.946214\n",
      "Epoch - 6\n",
      "Epoch - 6 Train Loss - 0.184572 Val Loss - 0.168895 Train Accuracy - 0.948391 Val Accuracy - 0.952660\n",
      "Epoch - 7\n",
      "Epoch - 7 Train Loss - 0.164824 Val Loss - 0.153480 Train Accuracy - 0.954096 Val Accuracy - 0.956641\n",
      "Epoch - 8\n",
      "Epoch - 8 Train Loss - 0.149853 Val Loss - 0.141806 Train Accuracy - 0.958857 Val Accuracy - 0.960708\n",
      "Epoch - 9\n",
      "Epoch - 9 Train Loss - 0.137225 Val Loss - 0.131138 Train Accuracy - 0.962400 Val Accuracy - 0.962236\n",
      "Epoch - 10\n",
      "Epoch - 10 Train Loss - 0.126464 Val Loss - 0.120090 Train Accuracy - 0.964921 Val Accuracy - 0.965654\n",
      "Epoch - 11\n",
      "Epoch - 11 Train Loss - 0.116853 Val Loss - 0.113623 Train Accuracy - 0.968093 Val Accuracy - 0.968158\n",
      "Epoch - 12\n",
      "Epoch - 12 Train Loss - 0.108853 Val Loss - 0.108541 Train Accuracy - 0.970289 Val Accuracy - 0.969037\n",
      "Epoch - 13\n",
      "Epoch - 13 Train Loss - 0.102385 Val Loss - 0.101063 Train Accuracy - 0.971448 Val Accuracy - 0.971324\n",
      "Epoch - 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [09:00<03:42, 111.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 14 Train Loss - 0.097061 Val Loss - 0.096408 Train Accuracy - 0.973451 Val Accuracy - 0.971662\n",
      "Notebook\n",
      "Epoch - 0\n",
      "Epoch - 0 Train Loss - 1.973876 Val Loss - 1.631400 Train Accuracy - 0.596765 Val Accuracy - 0.756119\n",
      "Epoch - 1\n",
      "Epoch - 1 Train Loss - 1.375455 Val Loss - 1.109080 Train Accuracy - 0.782015 Val Accuracy - 0.824049\n",
      "Epoch - 2\n",
      "Epoch - 2 Train Loss - 0.952271 Val Loss - 0.781038 Train Accuracy - 0.832639 Val Accuracy - 0.864285\n",
      "Epoch - 3\n",
      "Epoch - 3 Train Loss - 0.697092 Val Loss - 0.591647 Train Accuracy - 0.866287 Val Accuracy - 0.884876\n",
      "Epoch - 4\n",
      "Epoch - 4 Train Loss - 0.547201 Val Loss - 0.477228 Train Accuracy - 0.885576 Val Accuracy - 0.901527\n",
      "Epoch - 5\n",
      "Epoch - 5 Train Loss - 0.454305 Val Loss - 0.404975 Train Accuracy - 0.898405 Val Accuracy - 0.910785\n",
      "Epoch - 6\n",
      "Epoch - 6 Train Loss - 0.393663 Val Loss - 0.354168 Train Accuracy - 0.906737 Val Accuracy - 0.917801\n",
      "Epoch - 7\n",
      "Epoch - 7 Train Loss - 0.347955 Val Loss - 0.319631 Train Accuracy - 0.913831 Val Accuracy - 0.920451\n",
      "Epoch - 8\n",
      "Epoch - 8 Train Loss - 0.316905 Val Loss - 0.290796 Train Accuracy - 0.918792 Val Accuracy - 0.927554\n",
      "Epoch - 9\n",
      "Epoch - 9 Train Loss - 0.288964 Val Loss - 0.268183 Train Accuracy - 0.924935 Val Accuracy - 0.931342\n",
      "Epoch - 10\n",
      "Epoch - 10 Train Loss - 0.268029 Val Loss - 0.249911 Train Accuracy - 0.929785 Val Accuracy - 0.934923\n",
      "Epoch - 11\n",
      "Epoch - 11 Train Loss - 0.250379 Val Loss - 0.234709 Train Accuracy - 0.933123 Val Accuracy - 0.937514\n",
      "Epoch - 12\n",
      "Epoch - 12 Train Loss - 0.234187 Val Loss - 0.220477 Train Accuracy - 0.936955 Val Accuracy - 0.941672\n",
      "Epoch - 13\n",
      "Epoch - 13 Train Loss - 0.220451 Val Loss - 0.208549 Train Accuracy - 0.940682 Val Accuracy - 0.943131\n",
      "Epoch - 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [10:14<01:37, 97.95s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 14 Train Loss - 0.207326 Val Loss - 0.197571 Train Accuracy - 0.943968 Val Accuracy - 0.946959\n",
      "Notebook\n",
      "Epoch - 0\n",
      "Epoch - 0 Train Loss - 2.124531 Val Loss - 1.919305 Train Accuracy - 0.538419 Val Accuracy - 0.705643\n",
      "Epoch - 1\n",
      "Epoch - 1 Train Loss - 1.759254 Val Loss - 1.567566 Train Accuracy - 0.714494 Val Accuracy - 0.786413\n",
      "Epoch - 2\n",
      "Epoch - 2 Train Loss - 1.433450 Val Loss - 1.266770 Train Accuracy - 0.783126 Val Accuracy - 0.807769\n",
      "Epoch - 3\n",
      "Epoch - 3 Train Loss - 1.163809 Val Loss - 1.030812 Train Accuracy - 0.814548 Val Accuracy - 0.837728\n",
      "Epoch - 4\n",
      "Epoch - 4 Train Loss - 0.954296 Val Loss - 0.848357 Train Accuracy - 0.837209 Val Accuracy - 0.860563\n",
      "Epoch - 5\n",
      "Epoch - 5 Train Loss - 0.797423 Val Loss - 0.715513 Train Accuracy - 0.855184 Val Accuracy - 0.874419\n",
      "Epoch - 6\n",
      "Epoch - 6 Train Loss - 0.681762 Val Loss - 0.615564 Train Accuracy - 0.868900 Val Accuracy - 0.886609\n",
      "Epoch - 7\n",
      "Epoch - 7 Train Loss - 0.595684 Val Loss - 0.542147 Train Accuracy - 0.878823 Val Accuracy - 0.893509\n",
      "Epoch - 8\n",
      "Epoch - 8 Train Loss - 0.530424 Val Loss - 0.488514 Train Accuracy - 0.887692 Val Accuracy - 0.897015\n",
      "Epoch - 9\n",
      "Epoch - 9 Train Loss - 0.479704 Val Loss - 0.442635 Train Accuracy - 0.893962 Val Accuracy - 0.901965\n",
      "Epoch - 10\n",
      "Epoch - 10 Train Loss - 0.439228 Val Loss - 0.407929 Train Accuracy - 0.899795 Val Accuracy - 0.908965\n",
      "Epoch - 11\n",
      "Epoch - 11 Train Loss - 0.406551 Val Loss - 0.382815 Train Accuracy - 0.904249 Val Accuracy - 0.909064\n",
      "Epoch - 12\n",
      "Epoch - 12 Train Loss - 0.379478 Val Loss - 0.356335 Train Accuracy - 0.907947 Val Accuracy - 0.913832\n",
      "Epoch - 13\n",
      "Epoch - 13 Train Loss - 0.356781 Val Loss - 0.333073 Train Accuracy - 0.912737 Val Accuracy - 0.919035\n",
      "Epoch - 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [11:30<00:00, 115.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 14 Train Loss - 0.337240 Val Loss - 0.316037 Train Accuracy - 0.915197 Val Accuracy - 0.921635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batch_ = [8, 32, 128, 512, 2048, 4016]\n",
    "train_loss_ = []\n",
    "val_loss_ = []\n",
    "train_acc_ = []\n",
    "val_acc_ = []\n",
    "sensitivity_ = []\n",
    "for batch_size in tqdm(batch_):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    dataset1 = datasets.MNIST('Home work', train=True, download=True, transform=transform)\n",
    "    dataset2 = datasets.MNIST('Home work', train=False, transform=transform)\n",
    "\n",
    "    training_DataLoader = DataLoader(dataset1, batch_size=batch_size, shuffle=True)\n",
    "    validation_DataLoader = DataLoader(dataset2, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    model = CNN2()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    trainer = Trainer(model=model,\n",
    "                      device=gpu_id,\n",
    "                      criterion=loss_fn,\n",
    "                      optimizer=optimizer,\n",
    "                      training_DataLoader=training_DataLoader,\n",
    "                      validation_DataLoader=validation_DataLoader,\n",
    "                      # lr_scheduler=lr_scheduler,\n",
    "                      epochs=epochs,\n",
    "                      epoch=0,\n",
    "                      notebook=True,\n",
    "                      path2write=path2write,\n",
    "                      checkpoint_start_epoch=checkpoint_start_epoch)\n",
    "    training_loss, training_accuracy, validation_loss, validation_accuracy, sensitivity = trainer.run_trainer()\n",
    "    train_loss_.append(training_loss)\n",
    "    val_loss_.append(validation_loss)\n",
    "    train_acc_.append(training_accuracy)\n",
    "    val_acc_.append(validation_accuracy)\n",
    "    sensitivity_.append(sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b3fb13a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABMkAAAGyCAYAAAD+jZMxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAiBklEQVR4nO3df2zV9b348VdpoVXvbRdh1iLY1V3c5Y6MXdrIpdxm0WkNGG5ItlDjjVUvJrfZdgn0ahRJdBCT5po7c68/qFsEzRJ0jT/DH42jWe7lh3CT0bRmkeZuEa6FrZUUsxZ1twh8vn/4pd9v16KcQ38w3o9Hcv7oe+/POa9j8hZ57nNOC7IsywIAAAAAEjZjugcAAAAAgOkmkgEAAACQPJEMAAAAgOSJZAAAAAAkTyQDAAAAIHkiGQAAAADJE8kAAAAASJ5IBgAAAEDyRDIAAAAAkieSAQAAAJC8nCPZnj17YtWqVTF37twoKCiIN9988wuv2b17d1RXV0dJSUnccMMN8dxzz+UzKwAAAABMipwj2ccffxyLFy+OZ5555oL2HzlyJFauXBl1dXXR1dUVjzzySKxbty5ee+21nIcFAAAAgMlQkGVZlvfFBQXxxhtvxOrVq8+756GHHoqdO3dGT0/PyFpTU1O88847ceDAgXxfGgAAAAAmTNFkv8CBAweivr5+1Nrtt98e27Zti08//TRmzpw55prh4eEYHh4e+fns2bPx4YcfxuzZs6OgoGCyRwYAAADgEpVlWZw8eTLmzp0bM2ZM3NftT3ok6+/vj/Ly8lFr5eXlcfr06RgYGIiKioox17S0tMTmzZsnezQAAAAA/kQdPXo05s2bN2HPN+mRLCLG3P117hOe57srbOPGjdHc3Dzy8+DgYFx//fVx9OjRKC0tnbxBAQAAALikDQ0Nxfz58+PP//zPJ/R5Jz2SXXvttdHf3z9q7fjx41FUVBSzZ88e95ri4uIoLi4es15aWiqSAQAAADDhX8k1cR/cPI9ly5ZFR0fHqLVdu3ZFTU3NuN9HBgAAAABTLedI9tFHH0V3d3d0d3dHRMSRI0eiu7s7ent7I+Kzj0o2NjaO7G9qaor3338/mpubo6enJ7Zv3x7btm2LBx54YGLeAQAAAABcpJw/bnnw4MG4+eabR34+991h99xzT7z44ovR19c3EswiIqqqqqK9vT02bNgQzz77bMydOzeeeuqp+M53vjMB4wMAAADAxSvIzn2L/iVsaGgoysrKYnBw0HeSAQAAACRssjrRpH8nGQAAAABc6kQyAAAAAJInkgEAAACQPJEMAAAAgOSJZAAAAAAkTyQDAAAAIHkiGQAAAADJE8kAAAAASJ5IBgAAAEDyRDIAAAAAkieSAQAAAJA8kQwAAACA5IlkAAAAACRPJAMAAAAgeSIZAAAAAMkTyQAAAABInkgGAAAAQPJEMgAAAACSJ5IBAAAAkDyRDAAAAIDkiWQAAAAAJE8kAwAAACB5IhkAAAAAyRPJAAAAAEieSAYAAABA8kQyAAAAAJInkgEAAACQPJEMAAAAgOSJZAAAAAAkTyQDAAAAIHkiGQAAAADJE8kAAAAASJ5IBgAAAEDyRDIAAAAAkieSAQAAAJA8kQwAAACA5IlkAAAAACRPJAMAAAAgeSIZAAAAAMkTyQAAAABInkgGAAAAQPJEMgAAAACSJ5IBAAAAkDyRDAAAAIDkiWQAAAAAJE8kAwAAACB5IhkAAAAAyRPJAAAAAEieSAYAAABA8kQyAAAAAJInkgEAAACQPJEMAAAAgOSJZAAAAAAkTyQDAAAAIHkiGQAAAADJE8kAAAAASJ5IBgAAAEDyRDIAAAAAkieSAQAAAJA8kQwAAACA5IlkAAAAACRPJAMAAAAgeSIZAAAAAMkTyQAAAABInkgGAAAAQPJEMgAAAACSl1ck27p1a1RVVUVJSUlUV1fH3r17P3f/jh07YvHixXHllVdGRUVF3HfffXHixIm8BgYAAACAiZZzJGtra4v169fHpk2boqurK+rq6mLFihXR29s77v59+/ZFY2NjrF27Nt5999145ZVX4pe//GXcf//9Fz08AAAAAEyEnCPZk08+GWvXro37778/Fi5cGP/2b/8W8+fPj9bW1nH3/9d//Vd85StfiXXr1kVVVVX87d/+bfzjP/5jHDx48KKHBwAAAICJkFMkO3XqVHR2dkZ9ff2o9fr6+ti/f/+419TW1saxY8eivb09siyLDz74IF599dW44447zvs6w8PDMTQ0NOoBAAAAAJMlp0g2MDAQZ86cifLy8lHr5eXl0d/fP+41tbW1sWPHjmhoaIhZs2bFtddeG1/60pfi6aefPu/rtLS0RFlZ2chj/vz5uYwJAAAAADnJ64v7CwoKRv2cZdmYtXMOHToU69ati0cffTQ6OzvjrbfeiiNHjkRTU9N5n3/jxo0xODg48jh69Gg+YwIAAADABSnKZfOcOXOisLBwzF1jx48fH3N32TktLS2xfPnyePDBByMi4hvf+EZcddVVUVdXF48//nhUVFSMuaa4uDiKi4tzGQ0AAAAA8pbTnWSzZs2K6urq6OjoGLXe0dERtbW1417zySefxIwZo1+msLAwIj67Aw0AAAAAplvOH7dsbm6O559/PrZv3x49PT2xYcOG6O3tHfn45MaNG6OxsXFk/6pVq+L111+P1tbWOHz4cLz99tuxbt26uOmmm2Lu3LkT904AAAAAIE85fdwyIqKhoSFOnDgRW7Zsib6+vli0aFG0t7dHZWVlRET09fVFb2/vyP577703Tp48Gc8880z88z//c3zpS1+KW265Jf7lX/5l4t4FAAAAAFyEguxP4DOPQ0NDUVZWFoODg1FaWjrd4wAAAAAwTSarE+X12y0BAAAA4HIikgEAAACQPJEMAAAAgOSJZAAAAAAkTyQDAAAAIHkiGQAAAADJE8kAAAAASJ5IBgAAAEDyRDIAAAAAkieSAQAAAJA8kQwAAACA5IlkAAAAACRPJAMAAAAgeSIZAAAAAMkTyQAAAABInkgGAAAAQPJEMgAAAACSJ5IBAAAAkDyRDAAAAIDkiWQAAAAAJE8kAwAAACB5IhkAAAAAyRPJAAAAAEieSAYAAABA8kQyAAAAAJInkgEAAACQPJEMAAAAgOSJZAAAAAAkTyQDAAAAIHkiGQAAAADJE8kAAAAASJ5IBgAAAEDyRDIAAAAAkieSAQAAAJA8kQwAAACA5IlkAAAAACRPJAMAAAAgeSIZAAAAAMkTyQAAAABInkgGAAAAQPJEMgAAAACSJ5IBAAAAkDyRDAAAAIDkiWQAAAAAJE8kAwAAACB5IhkAAAAAyRPJAAAAAEieSAYAAABA8kQyAAAAAJInkgEAAACQPJEMAAAAgOSJZAAAAAAkTyQDAAAAIHkiGQAAAADJE8kAAAAASJ5IBgAAAEDyRDIAAAAAkieSAQAAAJA8kQwAAACA5IlkAAAAACRPJAMAAAAgeSIZAAAAAMkTyQAAAABInkgGAAAAQPJEMgAAAACSJ5IBAAAAkLy8ItnWrVujqqoqSkpKorq6Ovbu3fu5+4eHh2PTpk1RWVkZxcXF8dWvfjW2b9+e18AAAAAAMNGKcr2gra0t1q9fH1u3bo3ly5fHj3/841ixYkUcOnQorr/++nGvWbNmTXzwwQexbdu2+Iu/+Is4fvx4nD59+qKHBwAAAICJUJBlWZbLBUuXLo0lS5ZEa2vryNrChQtj9erV0dLSMmb/W2+9FXfeeWccPnw4rr766ryGHBoairKyshgcHIzS0tK8ngMAAACAP32T1Yly+rjlqVOnorOzM+rr60et19fXx/79+8e9ZufOnVFTUxNPPPFEXHfddXHjjTfGAw88EH/4wx/O+zrDw8MxNDQ06gEAAAAAkyWnj1sODAzEmTNnory8fNR6eXl59Pf3j3vN4cOHY9++fVFSUhJvvPFGDAwMxPe+97348MMPz/u9ZC0tLbF58+ZcRgMAAACAvOX1xf0FBQWjfs6ybMzaOWfPno2CgoLYsWNH3HTTTbFy5cp48skn48UXXzzv3WQbN26MwcHBkcfRo0fzGRMAAAAALkhOd5LNmTMnCgsLx9w1dvz48TF3l51TUVER1113XZSVlY2sLVy4MLIsi2PHjsWCBQvGXFNcXBzFxcW5jAYAAAAAecvpTrJZs2ZFdXV1dHR0jFrv6OiI2traca9Zvnx5/O53v4uPPvpoZO3Xv/51zJgxI+bNm5fHyAAAAAAwsXL+uGVzc3M8//zzsX379ujp6YkNGzZEb29vNDU1RcRnH5VsbGwc2X/XXXfF7Nmz47777otDhw7Fnj174sEHH4x/+Id/iCuuuGLi3gkAAAAA5Cmnj1tGRDQ0NMSJEydiy5Yt0dfXF4sWLYr29vaorKyMiIi+vr7o7e0d2f9nf/Zn0dHREf/0T/8UNTU1MXv27FizZk08/vjjE/cuAAAAAOAiFGRZlk33EF9kaGgoysrKYnBwMEpLS6d7HAAAAACmyWR1orx+uyUAAAAAXE5EMgAAAACSJ5IBAAAAkDyRDAAAAIDkiWQAAAAAJE8kAwAAACB5IhkAAAAAyRPJAAAAAEieSAYAAABA8kQyAAAAAJInkgEAAACQPJEMAAAAgOSJZAAAAAAkTyQDAAAAIHkiGQAAAADJE8kAAAAASJ5IBgAAAEDyRDIAAAAAkieSAQAAAJA8kQwAAACA5IlkAAAAACRPJAMAAAAgeSIZAAAAAMkTyQAAAABInkgGAAAAQPJEMgAAAACSJ5IBAAAAkDyRDAAAAIDkiWQAAAAAJE8kAwAAACB5IhkAAAAAyRPJAAAAAEieSAYAAABA8kQyAAAAAJInkgEAAACQPJEMAAAAgOSJZAAAAAAkTyQDAAAAIHkiGQAAAADJE8kAAAAASJ5IBgAAAEDyRDIAAAAAkieSAQAAAJA8kQwAAACA5IlkAAAAACRPJAMAAAAgeSIZAAAAAMkTyQAAAABInkgGAAAAQPJEMgAAAACSJ5IBAAAAkDyRDAAAAIDkiWQAAAAAJE8kAwAAACB5IhkAAAAAyRPJAAAAAEieSAYAAABA8kQyAAAAAJInkgEAAACQPJEMAAAAgOSJZAAAAAAkTyQDAAAAIHkiGQAAAADJE8kAAAAASJ5IBgAAAEDyRDIAAAAAkpdXJNu6dWtUVVVFSUlJVFdXx969ey/ourfffjuKiorim9/8Zj4vCwAAAACTIudI1tbWFuvXr49NmzZFV1dX1NXVxYoVK6K3t/dzrxscHIzGxsb49re/nfewAAAAADAZCrIsy3K5YOnSpbFkyZJobW0dWVu4cGGsXr06WlpaznvdnXfeGQsWLIjCwsJ48803o7u7+4Jfc2hoKMrKymJwcDBKS0tzGRcAAACAy8hkdaKc7iQ7depUdHZ2Rn19/aj1+vr62L9//3mve+GFF+K9996Lxx577IJeZ3h4OIaGhkY9AAAAAGCy5BTJBgYG4syZM1FeXj5qvby8PPr7+8e95je/+U08/PDDsWPHjigqKrqg12lpaYmysrKRx/z583MZEwAAAAByktcX9xcUFIz6OcuyMWsREWfOnIm77rorNm/eHDfeeOMFP//GjRtjcHBw5HH06NF8xgQAAACAC3Jht3b9X3PmzInCwsIxd40dP358zN1lEREnT56MgwcPRldXV/zgBz+IiIizZ89GlmVRVFQUu3btiltuuWXMdcXFxVFcXJzLaAAAAACQt5zuJJs1a1ZUV1dHR0fHqPWOjo6ora0ds7+0tDR+9atfRXd398ijqakpvva1r0V3d3csXbr04qYHAAAAgAmQ051kERHNzc1x9913R01NTSxbtix+8pOfRG9vbzQ1NUXEZx+V/O1vfxs//elPY8aMGbFo0aJR119zzTVRUlIyZh0AAAAApkvOkayhoSFOnDgRW7Zsib6+vli0aFG0t7dHZWVlRET09fVFb2/vhA8KAAAAAJOlIMuybLqH+CJDQ0NRVlYWg4ODUVpaOt3jAAAAADBNJqsT5fXbLQEAAADgciKSAQAAAJA8kQwAAACA5IlkAAAAACRPJAMAAAAgeSIZAAAAAMkTyQAAAABInkgGAAAAQPJEMgAAAACSJ5IBAAAAkDyRDAAAAIDkiWQAAAAAJE8kAwAAACB5IhkAAAAAyRPJAAAAAEieSAYAAABA8kQyAAAAAJInkgEAAACQPJEMAAAAgOSJZAAAAAAkTyQDAAAAIHkiGQAAAADJE8kAAAAASJ5IBgAAAEDyRDIAAAAAkieSAQAAAJA8kQwAAACA5IlkAAAAACRPJAMAAAAgeSIZAAAAAMkTyQAAAABInkgGAAAAQPJEMgAAAACSJ5IBAAAAkDyRDAAAAIDkiWQAAAAAJE8kAwAAACB5IhkAAAAAyRPJAAAAAEieSAYAAABA8kQyAAAAAJInkgEAAACQPJEMAAAAgOSJZAAAAAAkTyQDAAAAIHkiGQAAAADJE8kAAAAASJ5IBgAAAEDyRDIAAAAAkieSAQAAAJA8kQwAAACA5IlkAAAAACRPJAMAAAAgeSIZAAAAAMkTyQAAAABInkgGAAAAQPJEMgAAAACSJ5IBAAAAkDyRDAAAAIDkiWQAAAAAJE8kAwAAACB5IhkAAAAAyRPJAAAAAEieSAYAAABA8kQyAAAAAJInkgEAAACQvLwi2datW6OqqipKSkqiuro69u7de969r7/+etx2223x5S9/OUpLS2PZsmXx85//PO+BAQAAAGCi5RzJ2traYv369bFp06bo6uqKurq6WLFiRfT29o67f8+ePXHbbbdFe3t7dHZ2xs033xyrVq2Krq6uix4eAAAAACZCQZZlWS4XLF26NJYsWRKtra0jawsXLozVq1dHS0vLBT3H17/+9WhoaIhHH330gvYPDQ1FWVlZDA4ORmlpaS7jAgAAAHAZmaxOlNOdZKdOnYrOzs6or68ftV5fXx/79++/oOc4e/ZsnDx5Mq6++urz7hkeHo6hoaFRDwAAAACYLDlFsoGBgThz5kyUl5ePWi8vL4/+/v4Leo4f/ehH8fHHH8eaNWvOu6elpSXKyspGHvPnz89lTAAAAADISV5f3F9QUDDq5yzLxqyN5+WXX44f/vCH0dbWFtdcc815923cuDEGBwdHHkePHs1nTAAAAAC4IEW5bJ4zZ04UFhaOuWvs+PHjY+4u+2NtbW2xdu3aeOWVV+LWW2/93L3FxcVRXFycy2gAAAAAkLec7iSbNWtWVFdXR0dHx6j1jo6OqK2tPe91L7/8ctx7773x0ksvxR133JHfpAAAAAAwSXK6kywiorm5Oe6+++6oqamJZcuWxU9+8pPo7e2NpqamiPjso5K//e1v46c//WlEfBbIGhsb49///d/jb/7mb0buQrviiiuirKxsAt8KAAAAAOQn50jW0NAQJ06ciC1btkRfX18sWrQo2tvbo7KyMiIi+vr6ore3d2T/j3/84zh9+nR8//vfj+9///sj6/fcc0+8+OKLF/8OAAAAAOAiFWRZlk33EF9kaGgoysrKYnBwMEpLS6d7HAAAAACmyWR1orx+uyUAAAAAXE5EMgAAAACSJ5IBAAAAkDyRDAAAAIDkiWQAAAAAJE8kAwAAACB5IhkAAAAAyRPJAAAAAEieSAYAAABA8kQyAAAAAJInkgEAAACQPJEMAAAAgOSJZAAAAAAkTyQDAAAAIHkiGQAAAADJE8kAAAAASJ5IBgAAAEDyRDIAAAAAkieSAQAAAJA8kQwAAACA5IlkAAAAACRPJAMAAAAgeSIZAAAAAMkTyQAAAABInkgGAAAAQPJEMgAAAACSJ5IBAAAAkDyRDAAAAIDkiWQAAAAAJE8kAwAAACB5IhkAAAAAyRPJAAAAAEieSAYAAABA8kQyAAAAAJInkgEAAACQPJEMAAAAgOSJZAAAAAAkTyQDAAAAIHkiGQAAAADJE8kAAAAASJ5IBgAAAEDyRDIAAAAAkieSAQAAAJA8kQwAAACA5IlkAAAAACRPJAMAAAAgeSIZAAAAAMkTyQAAAABInkgGAAAAQPJEMgAAAACSJ5IBAAAAkDyRDAAAAIDkiWQAAAAAJE8kAwAAACB5IhkAAAAAyRPJAAAAAEieSAYAAABA8kQyAAAAAJInkgEAAACQPJEMAAAAgOSJZAAAAAAkTyQDAAAAIHkiGQAAAADJE8kAAAAASJ5IBgAAAEDyRDIAAAAAkpdXJNu6dWtUVVVFSUlJVFdXx969ez93/+7du6O6ujpKSkrihhtuiOeeey6vYQEAAABgMuQcydra2mL9+vWxadOm6Orqirq6ulixYkX09vaOu//IkSOxcuXKqKuri66urnjkkUdi3bp18dprr1308AAAAAAwEQqyLMtyuWDp0qWxZMmSaG1tHVlbuHBhrF69OlpaWsbsf+ihh2Lnzp3R09MzstbU1BTvvPNOHDhw4IJec2hoKMrKymJwcDBKS0tzGRcAAACAy8hkdaKiXDafOnUqOjs74+GHHx61Xl9fH/v37x/3mgMHDkR9ff2otdtvvz22bdsWn376acycOXPMNcPDwzE8PDzy8+DgYER89g8BAAAAgHSd60M53vf1hXKKZAMDA3HmzJkoLy8ftV5eXh79/f3jXtPf3z/u/tOnT8fAwEBUVFSMuaalpSU2b948Zn3+/Pm5jAsAAADAZerEiRNRVlY2Yc+XUyQ7p6CgYNTPWZaNWfui/eOtn7Nx48Zobm4e+fn3v/99VFZWRm9v74S+eeDiDQ0Nxfz58+Po0aM+Dg2XIGcULl3OJ1zanFG4dA0ODsb1118fV1999YQ+b06RbM6cOVFYWDjmrrHjx4+PuVvsnGuvvXbc/UVFRTF79uxxrykuLo7i4uIx62VlZf7lBJeo0tJS5xMuYc4oXLqcT7i0OaNw6ZoxI+ffR/n5z5fL5lmzZkV1dXV0dHSMWu/o6Ija2tpxr1m2bNmY/bt27Yqamppxv48MAAAAAKZazsmtubk5nn/++di+fXv09PTEhg0bore3N5qamiLis49KNjY2juxvamqK999/P5qbm6Onpye2b98e27ZtiwceeGDi3gUAAAAAXIScv5OsoaEhTpw4EVu2bIm+vr5YtGhRtLe3R2VlZURE9PX1RW9v78j+qqqqaG9vjw0bNsSzzz4bc+fOjaeeeiq+853vXPBrFhcXx2OPPTbuRzCB6eV8wqXNGYVLl/MJlzZnFC5dk3U+C7KJ/n2ZAAAAAPAnZmK/4QwAAAAA/gSJZAAAAAAkTyQDAAAAIHkiGQAAAADJu2Qi2datW6OqqipKSkqiuro69u7d+7n7d+/eHdXV1VFSUhI33HBDPPfcc1M0KaQnl/P5+uuvx2233RZf/vKXo7S0NJYtWxY///nPp3BaSE+uf4ae8/bbb0dRUVF885vfnNwBIWG5ns/h4eHYtGlTVFZWRnFxcXz1q1+N7du3T9G0kJ5cz+iOHTti8eLFceWVV0ZFRUXcd999ceLEiSmaFtKxZ8+eWLVqVcydOzcKCgrizTff/MJrJqITXRKRrK2tLdavXx+bNm2Krq6uqKurixUrVkRvb++4+48cORIrV66Murq66OrqikceeSTWrVsXr7322hRPDpe/XM/nnj174rbbbov29vbo7OyMm2++OVatWhVdXV1TPDmkIdczes7g4GA0NjbGt7/97SmaFNKTz/lcs2ZN/OIXv4ht27bFf//3f8fLL78cf/mXfzmFU0M6cj2j+/bti8bGxli7dm28++678corr8Qvf/nLuP/++6d4crj8ffzxx7F48eJ45plnLmj/RHWigizLsnwGnkhLly6NJUuWRGtr68jawoULY/Xq1dHS0jJm/0MPPRQ7d+6Mnp6ekbWmpqZ455134sCBA1MyM6Qi1/M5nq9//evR0NAQjz766GSNCcnK94zeeeedsWDBgigsLIw333wzuru7p2BaSEuu5/Ott96KO++8Mw4fPhxXX331VI4KScr1jP7rv/5rtLa2xnvvvTey9vTTT8cTTzwRR48enZKZIUUFBQXxxhtvxOrVq8+7Z6I60bTfSXbq1Kno7OyM+vr6Uev19fWxf//+ca85cODAmP233357HDx4MD799NNJmxVSk8/5/GNnz56NkydP+o99mAT5ntEXXngh3nvvvXjssccme0RIVj7nc+fOnVFTUxNPPPFEXHfddXHjjTfGAw88EH/4wx+mYmRISj5ntLa2No4dOxbt7e2RZVl88MEH8eqrr8Ydd9wxFSMDn2OiOlHRRA+Wq4GBgThz5kyUl5ePWi8vL4/+/v5xr+nv7x93/+nTp2NgYCAqKiombV5IST7n84/96Ec/io8//jjWrFkzGSNC0vI5o7/5zW/i4Ycfjr1790ZR0bT/ZwBctvI5n4cPH459+/ZFSUlJvPHGGzEwMBDf+9734sMPP/S9ZDDB8jmjtbW1sWPHjmhoaIj//d//jdOnT8ff/d3fxdNPPz0VIwOfY6I60bTfSXZOQUHBqJ+zLBuz9kX7x1sHLl6u5/Ocl19+OX74wx9GW1tbXHPNNZM1HiTvQs/omTNn4q677orNmzfHjTfeOFXjQdJy+TP07NmzUVBQEDt27IibbropVq5cGU8++WS8+OKL7iaDSZLLGT106FCsW7cuHn300ejs7Iy33norjhw5Ek1NTVMxKvAFJqITTfv/hTxnzpwoLCwcU+uPHz8+pgKec+211467v6ioKGbPnj1ps0Jq8jmf57S1tcXatWvjlVdeiVtvvXUyx4Rk5XpGT548GQcPHoyurq74wQ9+EBGf/aU8y7IoKiqKXbt2xS233DIls8PlLp8/QysqKuK6666LsrKykbWFCxdGlmVx7NixWLBgwaTODCnJ54y2tLTE8uXL48EHH4yIiG984xtx1VVXRV1dXTz++OM+0QTTaKI60bTfSTZr1qyorq6Ojo6OUesdHR1RW1s77jXLli0bs3/Xrl1RU1MTM2fOnLRZITX5nM+Iz+4gu/fee+Oll17yHQ0wiXI9o6WlpfGrX/0quru7Rx5NTU3xta99Lbq7u2Pp0qVTNTpc9vL5M3T58uXxu9/9Lj766KORtV//+tcxY8aMmDdv3qTOC6nJ54x+8sknMWPG6L9CFxYWRsT/u2MFmB4T1omyS8DPfvazbObMmdm2bduyQ4cOZevXr8+uuuqq7H/+53+yLMuyhx9+OLv77rtH9h8+fDi78sorsw0bNmSHDh3Ktm3bls2cOTN79dVXp+stwGUr1/P50ksvZUVFRdmzzz6b9fX1jTx+//vfT9dbgMtarmf0jz322GPZ4sWLp2haSEuu5/PkyZPZvHnzsu9+97vZu+++m+3evTtbsGBBdv/990/XW4DLWq5n9IUXXsiKioqyrVu3Zu+99162b9++rKamJrvpppum6y3AZevkyZNZV1dX1tXVlUVE9uSTT2ZdXV3Z+++/n2XZ5HWiSyKSZVmWPfvss1llZWU2a9asbMmSJdnu3btH/rd77rkn+9a3vjVq/3/+539mf/3Xf53NmjUr+8pXvpK1trZO8cSQjlzO57e+9a0sIsY87rnnnqkfHBKR65+h/z+RDCZXruezp6cnu/XWW7MrrrgimzdvXtbc3Jx98sknUzw1pCPXM/rUU09lf/VXf5VdccUVWUVFRfb3f//32bFjx6Z4arj8/cd//Mfn/r1ysjpRQZa5LxQAAACAtE37d5IBAAAAwHQTyQAAAABInkgGAAAAQPJEMgAAAACSJ5IBAAAAkDyRDAAAAIDkiWQAAAAAJE8kAwAAACB5IhkAAAAAyRPJAAAAAEieSAYAAABA8kQyAAAAAJL3fwCyjA9Hx2BJCgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(15, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "227b7619",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Batch Size Vs loss Vs Sensitivity')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ax1 = fig.add_subplot(1, 1, 1)\n",
    "ax1.plot(batch_, train_loss_, 'b-', label='Train')\n",
    "ax1.plot(batch_, val_loss_, 'b--', label='Validation')\n",
    "ax1.legend()\n",
    "ax1.set_xlabel('Batch Size')\n",
    "ax1.set_ylabel('Loss', color='b')\n",
    "ax1.set_title('Batch Size Vs loss Vs Sensitivity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5f3f5a57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    }
   ],
   "source": [
    "ax2 = ax1.twinx()\n",
    "ax2.plot(batch_, sensitivity_, 'r-')\n",
    "ax2.legend()\n",
    "ax2.set_ylabel('Sensitivity', color='r')\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(path2write, 'sensitivity_loss.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "69d3a24e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(15, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6ff04d1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Batch Size Vs Accuracy Vs Sensitivity')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ax1 = fig.add_subplot(1, 1, 1)\n",
    "ax1.plot(batch_, train_acc_, 'b-', label='Train')\n",
    "ax1.plot(batch_, val_acc_, 'b--', label='Validation')\n",
    "ax1.legend()\n",
    "ax1.set_xlabel('Batch Size')\n",
    "ax1.set_ylabel('Accuracy', color='b')\n",
    "ax1.set_title('Batch Size Vs Accuracy Vs Sensitivity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dd8997fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    }
   ],
   "source": [
    "ax2 = ax1.twinx()\n",
    "ax2.plot(batch_, sensitivity_, 'r-')\n",
    "ax2.legend()\n",
    "ax2.set_ylabel('Sensitivity', color='r')\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(path2write, 'sensitivity_accuracy.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567a802e-e28d-49d5-b61b-919fca76cf7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
