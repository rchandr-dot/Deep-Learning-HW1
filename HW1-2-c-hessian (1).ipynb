{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "715d2c54-f792-4e2c-affb-afcd729ce09e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85423572",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import seaborn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44b96851",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70381588-73e4-4941-b41b-4513b340b819",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: autograd-lib in ./.local/lib/python3.11/site-packages (0.0.7)\n",
      "Requirement already satisfied: gin-config in ./.local/lib/python3.11/site-packages (from autograd-lib) (0.5.0)\n",
      "Requirement already satisfied: seaborn in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from autograd-lib) (0.12.2)\n",
      "Requirement already satisfied: pytorch-lightning in ./.local/lib/python3.11/site-packages (from autograd-lib) (2.4.0)\n",
      "Requirement already satisfied: torch>=2.1.0 in ./.local/lib/python3.11/site-packages (from pytorch-lightning->autograd-lib) (2.4.1)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from pytorch-lightning->autograd-lib) (4.65.0)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from pytorch-lightning->autograd-lib) (6.0)\n",
      "Requirement already satisfied: fsspec[http]>=2022.5.0 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from pytorch-lightning->autograd-lib) (2023.4.0)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in ./.local/lib/python3.11/site-packages (from pytorch-lightning->autograd-lib) (1.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from pytorch-lightning->autograd-lib) (23.1)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in ./.local/lib/python3.11/site-packages (from pytorch-lightning->autograd-lib) (4.12.2)\n",
      "Requirement already satisfied: lightning-utilities>=0.10.0 in ./.local/lib/python3.11/site-packages (from pytorch-lightning->autograd-lib) (0.11.7)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from seaborn->autograd-lib) (1.24.3)\n",
      "Requirement already satisfied: pandas>=0.25 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from seaborn->autograd-lib) (2.0.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from seaborn->autograd-lib) (3.7.2)\n",
      "Requirement already satisfied: requests in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning->autograd-lib) (2.31.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning->autograd-lib) (3.8.5)\n",
      "Requirement already satisfied: setuptools in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from lightning-utilities>=0.10.0->pytorch-lightning->autograd-lib) (68.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn->autograd-lib) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn->autograd-lib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn->autograd-lib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn->autograd-lib) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn->autograd-lib) (9.4.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn->autograd-lib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn->autograd-lib) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from pandas>=0.25->seaborn->autograd-lib) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from pandas>=0.25->seaborn->autograd-lib) (2023.3)\n",
      "Requirement already satisfied: filelock in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from torch>=2.1.0->pytorch-lightning->autograd-lib) (3.9.0)\n",
      "Requirement already satisfied: sympy in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from torch>=2.1.0->pytorch-lightning->autograd-lib) (1.11.1)\n",
      "Requirement already satisfied: networkx in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from torch>=2.1.0->pytorch-lightning->autograd-lib) (3.1)\n",
      "Requirement already satisfied: jinja2 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from torch>=2.1.0->pytorch-lightning->autograd-lib) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./.local/lib/python3.11/site-packages (from torch>=2.1.0->pytorch-lightning->autograd-lib) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./.local/lib/python3.11/site-packages (from torch>=2.1.0->pytorch-lightning->autograd-lib) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./.local/lib/python3.11/site-packages (from torch>=2.1.0->pytorch-lightning->autograd-lib) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./.local/lib/python3.11/site-packages (from torch>=2.1.0->pytorch-lightning->autograd-lib) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./.local/lib/python3.11/site-packages (from torch>=2.1.0->pytorch-lightning->autograd-lib) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./.local/lib/python3.11/site-packages (from torch>=2.1.0->pytorch-lightning->autograd-lib) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./.local/lib/python3.11/site-packages (from torch>=2.1.0->pytorch-lightning->autograd-lib) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./.local/lib/python3.11/site-packages (from torch>=2.1.0->pytorch-lightning->autograd-lib) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./.local/lib/python3.11/site-packages (from torch>=2.1.0->pytorch-lightning->autograd-lib) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in ./.local/lib/python3.11/site-packages (from torch>=2.1.0->pytorch-lightning->autograd-lib) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./.local/lib/python3.11/site-packages (from torch>=2.1.0->pytorch-lightning->autograd-lib) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in ./.local/lib/python3.11/site-packages (from torch>=2.1.0->pytorch-lightning->autograd-lib) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./.local/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.1.0->pytorch-lightning->autograd-lib) (12.6.68)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->autograd-lib) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->autograd-lib) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->autograd-lib) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->autograd-lib) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->autograd-lib) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->autograd-lib) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->autograd-lib) (1.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn->autograd-lib) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from jinja2->torch>=2.1.0->pytorch-lightning->autograd-lib) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning->autograd-lib) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning->autograd-lib) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning->autograd-lib) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from sympy->torch>=2.1.0->pytorch-lightning->autograd-lib) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install autograd-lib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "400bf040",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from autograd_lib import autograd_lib\n",
    "from collections import defaultdict\n",
    "import random\n",
    "#\n",
    "# def seed_all(n=1998):\n",
    "#     torch.manual_seed(n)\n",
    "#     np.random.seed(n)\n",
    "#     random.seed(n)\n",
    "# seed_all(195)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b5ff4b5",
   "metadata": {
    "lines_to_next_cell": 1,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "\n",
    "    def __init__(self,\n",
    "                 model: torch.nn.Module,\n",
    "                 device: torch.device,\n",
    "                 criterion: torch.nn.Module,\n",
    "                 optimizer: torch.optim.Optimizer,\n",
    "                 training_DataLoader: torch.utils.data.Dataset,\n",
    "                 validation_DataLoader: None,\n",
    "                 # lr_scheduler: torch.optim.lr_scheduler = None,\n",
    "                 epochs: int = 100,\n",
    "                 epoch: int = 0,\n",
    "                 notebook: bool = False,\n",
    "                 path2write: str = None,\n",
    "                 save_best=False,\n",
    "                 save_final=True,\n",
    "                 save_interval=10,\n",
    "                 checkpoint_start_epoch=50,\n",
    "                 gradient_norm=False,\n",
    "                 min_ratio = True\n",
    "                 ):\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        # self.lr_scheduler = lr_scheduler\n",
    "        self.training_DataLoader = training_DataLoader\n",
    "        self.validation_DataLoader = validation_DataLoader\n",
    "        self.device = device\n",
    "        self.epochs = epochs\n",
    "        self.epoch = epoch\n",
    "        self.notebook = notebook\n",
    "        self.path2write = path2write\n",
    "        LOG_DIR = os.path.join(path2write, 'Log')  # path2write + 'Log/'\n",
    "        self.writer_train = SummaryWriter(os.path.join(LOG_DIR, \"train\"))\n",
    "        self.writer_val = SummaryWriter(os.path.join(LOG_DIR, \"val\"))\n",
    "        self.check_point_path = os.path.join(path2write, 'check_points')\n",
    "        if not os.path.exists(self.check_point_path):\n",
    "            os.makedirs(self.check_point_path)\n",
    "        self.save_best = save_best\n",
    "        self.save_final = save_final\n",
    "        self.save_interval = save_interval\n",
    "        self.checkpoint_start_epoch = checkpoint_start_epoch\n",
    "        self.training_loss = []\n",
    "        self.validation_loss = []\n",
    "        self.learning_rate = []\n",
    "        self.gradient_norm = gradient_norm\n",
    "        self.grad_list = []\n",
    "        self.min_ratio_list = []\n",
    "        self.min_ratio = min_ratio\n",
    "        self.activations = defaultdict(int)\n",
    "        self.hess = defaultdict(float)\n",
    "\n",
    "    def run_trainer(self):\n",
    "        self.model.to(self.device)\n",
    "        #         print(next(self.model.parameters()).device)\n",
    "        if self.notebook:\n",
    "            print('Notebook')\n",
    "            from tqdm.notebook import tqdm, trange\n",
    "        else:\n",
    "            from tqdm import tqdm, trange\n",
    "        #         print(self.epochs)\n",
    "        progressbar = trange(self.epochs, desc='Progress', disable=True)  # don't show progressbar\n",
    "        loss_max = None\n",
    "        min_ratio = None\n",
    "        for epoch in progressbar:\n",
    "            # print(f'Epoch - {epoch}')\n",
    "\n",
    "            # Training Block\n",
    "            train_loss = self._train()\n",
    "            # self.min_ratio_list.append(ratio_mean)\n",
    "            self.writer_train.add_scalar(\"Loss\", train_loss, epoch)\n",
    "\n",
    "            # Val Block\n",
    "            val_loss = self._validate()\n",
    "            self.writer_val.add_scalar(\"Loss\", val_loss, epoch)\n",
    "\n",
    "            # lr\n",
    "            self.writer_train.add_scalar(\"Learning Rate\", self.optimizer.param_groups[0]['lr'], epoch)\n",
    "\n",
    "            if self.save_final:\n",
    "                if epoch == self.epochs - 1:\n",
    "                    model_name = 'epoch-{}-loss{:.6f}'.format(epoch, val_loss)\n",
    "                    torch.save(self.model.state_dict(), os.path.join(self.check_point_path, model_name))\n",
    "\n",
    "            loss_max = val_loss\n",
    "\n",
    "            # if self.gradient_norm:\n",
    "            grad_all = 0.0\n",
    "            for p in self.model.parameters():\n",
    "                grad = 0.0\n",
    "                if p.grad is not None:\n",
    "                    grad = (p.grad.cpu().data.numpy() ** 2).sum()\n",
    "                    grad_all += grad\n",
    "            grad_norm = grad_all ** 0.5\n",
    "            # self.grad_list.append()\n",
    "\n",
    "            # print('Grad Norm {:.6f}'.format(grad_norm))\n",
    "            if grad_norm < 0.025:\n",
    "                min_ratio = self.compute_minimal_ratio(self.training_DataLoader.dataset.tensors[0], self.training_DataLoader.dataset.tensors[1])\n",
    "                self.min_ratio_list.append(min_ratio)\n",
    "                print('Epoch - {} Train Loss - {:.6f} Val Loss - {:.6f} Min Ratio - {:.6f}'.format(epoch, train_loss,\n",
    "                                                                                                   val_loss,\n",
    "                                                                                                   min_ratio))\n",
    "                break\n",
    "\n",
    "\n",
    "        return train_loss, min_ratio\n",
    "        # return self.training_loss, self.validation_loss, self.model\n",
    "\n",
    "    def _train(self):\n",
    "\n",
    "        self.model.train()\n",
    "        train_losses = []\n",
    "        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),\n",
    "                          disable=True)\n",
    "\n",
    "        for i, (x, y) in batch_iter: # x- batch X dims\n",
    "            input, target = x.type(torch.float32).to(self.device), y.type(torch.float32).to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "            output = self.model(input)\n",
    "            loss = self.criterion(output, target)\n",
    "            train_losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "        self.training_loss.append(np.mean(train_losses))  # Mean batch loss\n",
    "        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])\n",
    "\n",
    "\n",
    "        batch_iter.close()  # clean up the bar\n",
    "        return np.mean(train_losses)\n",
    "\n",
    "    def _validate(self):\n",
    "\n",
    "        self.model.eval()\n",
    "        valid_losses = []\n",
    "        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'validation', total=len(self.validation_DataLoader),\n",
    "                          disable=True)\n",
    "        for i, (x, y) in batch_iter:\n",
    "            input, target = x.type(torch.float32).to(self.device), y.type(torch.float32).to(self.device)\n",
    "            with torch.no_grad():\n",
    "                out = self.model(input)\n",
    "                loss = self.criterion(target, out)\n",
    "                valid_losses.append(loss.item())\n",
    "        self.validation_loss.append(np.mean(valid_losses))\n",
    "        batch_iter.close()\n",
    "        return np.mean(valid_losses)\n",
    "\n",
    "    def save_activations(self, layer, A, _):\n",
    "        self.activations[layer] = A\n",
    "\n",
    "    def compute_hess(self, layer, _, B):\n",
    "        A = self.activations[layer]\n",
    "        BA = torch.einsum('nl,ni->nli', B, A)  # do batch-wise outer product\n",
    "\n",
    "        # full Hessian\n",
    "        self.hess[layer] += torch.einsum('nli,nkj->likj', BA, BA)\n",
    "\n",
    "    def compute_minimal_ratio(self, train, target):\n",
    "        # model.to(device)\n",
    "        train = train.to(self.device)\n",
    "        target = target.to(self.device)\n",
    "        self.model.zero_grad()\n",
    "\n",
    "        # compute Hessian matrix\n",
    "        # save the gradient of each layer\n",
    "        with autograd_lib.module_hook(self.save_activations):\n",
    "            output = model(train)\n",
    "            loss = self.criterion(output, target)\n",
    "\n",
    "        # compute Hessian according to the gradient value stored in the previous step\n",
    "        with autograd_lib.module_hook(self.compute_hess):\n",
    "            autograd_lib.backward_hessian(output, loss='LeastSquares')\n",
    "\n",
    "        layer_hess = list(self.hess.values())\n",
    "        minimum_ratio = []\n",
    "\n",
    "        # compute eigenvalues of the Hessian matrix\n",
    "        for h in layer_hess:\n",
    "            size = h.shape[0] * h.shape[1]\n",
    "            h = h.reshape(size, size)\n",
    "            h_eig = torch.symeig(\n",
    "                h).eigenvalues  # torch.symeig() returns eigenvalues and eigenvectors of a real symmetric matrix\n",
    "            num_greater = torch.sum(h_eig > 0).item()\n",
    "            minimum_ratio.append((num_greater/len(h_eig)))\n",
    "\n",
    "        ratio_mean = np.mean(minimum_ratio)\n",
    "        return ratio_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec2225c9",
   "metadata": {
    "lines_to_next_cell": 1,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class model1(nn.Module):\n",
    "    def __init__(self, input_size=1, output_size=1):\n",
    "        super().__init__()\n",
    "        self.dense1 = nn.Linear(input_size, 10)\n",
    "        self.dense2 = nn.Linear(10, 18)\n",
    "        self.dense3 = nn.Linear(18, 15)\n",
    "        self.dense4 = nn.Linear(15, 4)\n",
    "        self.dense5 = nn.Linear(4, output_size)\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        x1 = F.relu(self.dense1(input_data))\n",
    "        x2 = F.relu(self.dense2(x1))\n",
    "        x3 = F.relu(self.dense3(x2))\n",
    "        x4 = F.relu(self.dense4(x3))\n",
    "        x5 = F.relu(self.dense5(x4))\n",
    "        return x5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1842c7b1",
   "metadata": {
    "lines_to_next_cell": 1,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SineApproximator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SineApproximator, self).__init__()\n",
    "        self.regressor = nn.Sequential(nn.Linear(1, 256),\n",
    "                                       nn.ReLU(inplace=True),\n",
    "                                       nn.Linear(256, 1))\n",
    "    def forward(self, x):\n",
    "        output = self.regressor(x)\n",
    "        return output\n",
    "class model2(nn.Module):\n",
    "    def __init__(self, input_size=1, output_size=1):\n",
    "        super(model2, self).__init__()\n",
    "        self.dense1 = nn.Linear(input_size, 128)\n",
    "        self.dense2 = nn.Linear(128, 64)\n",
    "        self.dense3 = nn.Linear(64, 1)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.dense1(x))\n",
    "        x = F.relu(self.dense2(x))\n",
    "        out = self.dense3(x)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d0d5d9c",
   "metadata": {
    "lines_to_next_cell": 1,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prep_data(func, data_length=2500, train_ratio=0.7, batch_size=8, shuffle=True):\n",
    "    X = np.linspace(1e-4, 1, data_length)\n",
    "    # np.random.shuffle(X)\n",
    "    y = np.array(list(map(func, X)))\n",
    "    X = X.reshape(X.shape[0], 1)\n",
    "    y = y.reshape(y.shape[0], 1)\n",
    "    X = torch.from_numpy(X).float()\n",
    "    y = torch.from_numpy(y).float()\n",
    "    X_train, X_val = X[0:int(data_length * train_ratio), ], X[int(data_length * train_ratio):, ]\n",
    "    y_train, y_val = y[0:int(data_length * train_ratio), ], y[int(data_length * train_ratio):, ]\n",
    "    assert X_train.shape[0] == y_train.shape[0]\n",
    "    assert X_val.shape[0] == y_val.shape[0]\n",
    "    TrainDataLoader = DataLoader(TensorDataset(X_train, y_train), batch_size, shuffle)\n",
    "    ValDataLoader = DataLoader(TensorDataset(X_val, y_val), batch_size, shuffle)\n",
    "\n",
    "    return TrainDataLoader, ValDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf4ed2eb",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "gpu_id = 0\n",
    "loss_fn = nn.MSELoss()\n",
    "lr = 1e-4\n",
    "func1 = lambda x: (np.sin(5 * (np.pi) * x)) / (5 * np.pi * x)\n",
    "func2 = lambda x: np.sign(np.sin(5*np.pi*x))\n",
    "training_DataLoader,  validation_DataLoader = prep_data(func=func1,batch_size=4096)\n",
    "epochs =  2000\n",
    "notebook = True\n",
    "checkpoint_start_epoch = 5 #Not using\n",
    "path2write = r\"/Users/ramya/Desktop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4c112d6-31df-4abf-853d-ba5b419cce2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path2write = os.path.expanduser(\"~/my_logs\")  # This will create a 'my_logs' directory in your home directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "102eff83",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rchandr/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n",
      "  1%|          | 1/100 [00:37<1:01:38, 37.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [01:14<1:00:25, 36.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [01:50<59:23, 36.74s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [02:27<58:50, 36.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [03:04<58:12, 36.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [03:42<58:33, 37.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [04:22<59:10, 38.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [05:01<59:08, 38.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [05:39<57:51, 38.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [06:16<56:45, 37.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [06:53<55:47, 37.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [07:30<54:54, 37.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [08:07<54:16, 37.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [08:45<53:43, 37.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [09:24<53:43, 37.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [10:03<53:26, 38.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [10:40<52:40, 38.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/100 [11:17<51:31, 37.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [11:55<50:50, 37.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [12:33<50:25, 37.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [13:12<50:03, 38.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [13:50<49:34, 38.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [14:29<49:10, 38.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/100 [15:07<48:38, 38.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25/100 [15:47<48:27, 38.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [16:26<48:04, 38.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [17:05<47:26, 38.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28/100 [17:45<46:58, 39.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [18:24<46:16, 39.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/100 [19:03<45:39, 39.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/100 [19:43<45:08, 39.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 32/100 [20:23<44:41, 39.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 33/100 [21:02<44:11, 39.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 34/100 [21:42<43:30, 39.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 34/100 [22:20<43:22, 39.43s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "This function was deprecated since version 1.9 and is now removed. The default behavior has changed from using the upper triangular portion of the matrix by default to using the lower triangular portion.\n\nL, _ = torch.symeig(A, upper=upper) should be replaced with:\nL = torch.linalg.eigvalsh(A, UPLO='U' if upper else 'L')\n\nand\n\nL, V = torch.symeig(A, eigenvectors=True) should be replaced with:\nL, V = torch.linalg.eigh(A, UPLO='U' if upper else 'L')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 23\u001b[0m\n\u001b[1;32m      9\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr \u001b[38;5;241m=\u001b[39m lr)\n\u001b[1;32m     10\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     11\u001b[0m                       device\u001b[38;5;241m=\u001b[39mgpu_id,\n\u001b[1;32m     12\u001b[0m                       criterion\u001b[38;5;241m=\u001b[39mloss_fn,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m                       checkpoint_start_epoch\u001b[38;5;241m=\u001b[39mcheckpoint_start_epoch,\n\u001b[1;32m     22\u001b[0m                       gradient_norm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 23\u001b[0m train_loss, min_ratio \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mrun_trainer()\n\u001b[1;32m     24\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n\u001b[1;32m     25\u001b[0m min_ratios\u001b[38;5;241m.\u001b[39mappend(min_ratio)\n",
      "Cell \u001b[0;32mIn[6], line 99\u001b[0m, in \u001b[0;36mTrainer.run_trainer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# self.grad_list.append()\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# print('Grad Norm {:.6f}'.format(grad_norm))\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grad_norm \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.025\u001b[39m:\n\u001b[0;32m---> 99\u001b[0m     min_ratio \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_minimal_ratio(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_DataLoader\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mtensors[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_DataLoader\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mtensors[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_ratio_list\u001b[38;5;241m.\u001b[39mappend(min_ratio)\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch - \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m Train Loss - \u001b[39m\u001b[38;5;132;01m{:.6f}\u001b[39;00m\u001b[38;5;124m Val Loss - \u001b[39m\u001b[38;5;132;01m{:.6f}\u001b[39;00m\u001b[38;5;124m Min Ratio - \u001b[39m\u001b[38;5;132;01m{:.6f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch, train_loss,\n\u001b[1;32m    102\u001b[0m                                                                                        val_loss,\n\u001b[1;32m    103\u001b[0m                                                                                        min_ratio))\n",
      "Cell \u001b[0;32mIn[6], line 182\u001b[0m, in \u001b[0;36mTrainer.compute_minimal_ratio\u001b[0;34m(self, train, target)\u001b[0m\n\u001b[1;32m    180\u001b[0m size \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m h\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    181\u001b[0m h \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mreshape(size, size)\n\u001b[0;32m--> 182\u001b[0m h_eig \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msymeig(\n\u001b[1;32m    183\u001b[0m     h)\u001b[38;5;241m.\u001b[39meigenvalues  \u001b[38;5;66;03m# torch.symeig() returns eigenvalues and eigenvectors of a real symmetric matrix\u001b[39;00m\n\u001b[1;32m    184\u001b[0m num_greater \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(h_eig \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    185\u001b[0m minimum_ratio\u001b[38;5;241m.\u001b[39mappend((num_greater\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(h_eig)))\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/_linalg_utils.py:116\u001b[0m, in \u001b[0;36m_symeig\u001b[0;34m(input, eigenvectors, upper, out)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_symeig\u001b[39m(\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28minput\u001b[39m, eigenvectors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, upper\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    115\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Tensor, Tensor]:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    117\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis function was deprecated since version 1.9 and is now removed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    118\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe default behavior has changed from using the upper triangular portion of the matrix by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    119\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto using the lower triangular portion.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    120\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL, _ = torch.symeig(A, upper=upper) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    121\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshould be replaced with:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL = torch.linalg.eigvalsh(A, UPLO=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mU\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m if upper else \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL, V = torch.symeig(A, eigenvectors=True) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    125\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshould be replaced with:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    126\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL, V = torch.linalg.eigh(A, UPLO=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mU\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m if upper else \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    127\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: This function was deprecated since version 1.9 and is now removed. The default behavior has changed from using the upper triangular portion of the matrix by default to using the lower triangular portion.\n\nL, _ = torch.symeig(A, upper=upper) should be replaced with:\nL = torch.linalg.eigvalsh(A, UPLO='U' if upper else 'L')\n\nand\n\nL, V = torch.symeig(A, eigenvectors=True) should be replaced with:\nL, V = torch.linalg.eigh(A, UPLO='U' if upper else 'L')"
     ]
    }
   ],
   "source": [
    "# model = model1()\n",
    "# model = SineApproximator()\n",
    "train_losses = []\n",
    "min_ratios = []\n",
    "for i in tqdm(range(100)):\n",
    "    # model = model2()\n",
    "    model = SineApproximator()\n",
    "    autograd_lib.register(model)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "    trainer = Trainer(model=model,\n",
    "                          device=gpu_id,\n",
    "                          criterion=loss_fn,\n",
    "                          optimizer=optimizer,\n",
    "                          training_DataLoader=training_DataLoader,\n",
    "                          validation_DataLoader=validation_DataLoader,\n",
    "                          # lr_scheduler=lr_scheduler,\n",
    "                          epochs=epochs,\n",
    "                          epoch=0,\n",
    "                          notebook=True,\n",
    "                          path2write= path2write,\n",
    "                          checkpoint_start_epoch=checkpoint_start_epoch,\n",
    "                          gradient_norm = True)\n",
    "    train_loss, min_ratio = trainer.run_trainer()\n",
    "    train_losses.append(train_loss)\n",
    "    min_ratios.append(min_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bc5ec04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(15, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bb11fc",
   "metadata": {},
   "source": [
    "ax1 = fig.add_subplot(1,2,1)\n",
    "ax1.plot(train_losses, 'r-', label='Training Loss')\n",
    "ax1.legend()\n",
    "ax1.set_title('Training Loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.savefig(os.path.join(path2write, 'Training Loss.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3077b448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ax2 = fig.add_subplot(1, 1, 1)\n",
    "ax2.scatter(min_ratios, train_losses, alpha=0.5, label='Minimum Ratio')\n",
    "ax2.legend()\n",
    "ax2.set_title('Minimal Ratio')\n",
    "ax2.set_xlabel('Minimal Ratio')\n",
    "ax2.set_ylabel('Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f710b9",
   "metadata": {},
   "source": [
    "extent = ax2.get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n",
    "fig.savefig('ax2_figure.png', bbox_inches=extent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b449a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('minimal ratio')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
